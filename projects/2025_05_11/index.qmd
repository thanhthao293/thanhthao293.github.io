---
title: "Analysis of Predictors Contributing to Social Anxiety"
date: 2025-05-11
author: Thao Nguyen
categories: [R, Statistical Analysis]
output: 
  html:
    highlight: haddock
    theme: journal
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,  message = FALSE, warning = FALSE, fig.align = "center")
```

```{r load libraries}
library(caret)
library(dplyr)
library(GGally)
library(ggcorrplot)
library(ggplot2)
library(gt)
library(pROC)
library(tidyr)
```

# 1. Introduction

Social anxiety is a persistent and impairing condition characterized by intense fear of social situations and negative evaluation by others. It can significantly affect daily functioning, relationships, and overall quality of life. While its causes are multifaceted, understanding which specific demographic, lifestyle, and psychological factors contribute to higher levels of social anxiety is critical for informing both clinical practices and future research on how to better support individuals dealing with social anxiety.

# 2. Methodology

## 2.1. Data

```{r read in data}
anxiety <- read.csv("enhanced_anxiety_dataset.csv")
```

```{r pre-process data}
anxiety_n <- anxiety %>%
  # rename columns
  rename(
    age = Age,
    gender = Gender,
    occupation = Occupation,
    sleep_hours = Sleep.Hours,
    physical_hours = Physical.Activity..hrs.week.,
    caffeine_daily = Caffeine.Intake..mg.day.,
    weekly_alcohol = Alcohol.Consumption..drinks.week.,
    smoking = Smoking,
    family_anxiety = Family.History.of.Anxiety,
    stress_level = Stress.Level..1.10.,
    heart_rate = Heart.Rate..bpm.,
    breathing_rate = Breathing.Rate..breaths.min.,
    sweating_level = Sweating.Level..1.5.,
    dizziness = Dizziness,
    medication = Medication,
    monthly_therapy = Therapy.Sessions..per.month.,
    recent_major_events = Recent.Major.Life.Event,
    diet_quality = Diet.Quality..1.10.,
    anxiety_level = Anxiety.Level..1.10.
  ) %>%
  # exclude these variables because of uncertainty
  select(-c(heart_rate, breathing_rate, sweating_level, dizziness)) %>%
  # convert some numeric variables to ordinal variables
  mutate(
    anxiety_level = factor(anxiety_level, levels = c(1:10), ordered = T),
    anxiety_status = factor(case_when(anxiety_level %in% 1:5 ~ "Low",
                                      TRUE ~ "High")),
    anxiety_status = relevel(anxiety_status, ref = "Low")
  ) %>%
  # remove `anxiety_level`
  select(-anxiety_level)

# set seed
set.seed(123)

# split data intro training and test set
train_index <- sample(1:nrow(anxiety_n), size = floor(0.8 * nrow(anxiety_n)))
train_data <- anxiety_n[train_index, ]
test_data <- anxiety_n[-train_index, ]
```

The dataset was obtained from a self-reported survey and distributed on Kaggle. It contains 11,000 observations and 19 variables, which are coded as follows:

1. `age`: Age of the participant
2. `gender`: Gender of the participant
3. `occupation`: Occupation of the participant
4. `sleep_hours`: Number of sleep hours the participant get
5. `physical_hours`: Hours spent on physical activity per day
6. `caffeine_daily`: Daily caffeine intake (mg/day)
7. `weekly_alcohol`: Weekly alcohol consumption (number of drinks)
8. `smoking`: Smoking status (yes/no)
9. `family_anxiety`: Family history of anxiety (yes/no)
10. `stress_level`: Self-reported stress level (scale of 1 to 10)
11. `heart_rate`: Heart rate (beats per minute)
12. `breathing_rate`: Breathing rate (breaths per minute)
13. `sweating_level`: Sweating level (scale of 1 to 5)
14. `dizziness`: Experience of dizziness (yes/no)
15. `medication`: Medication use (yes/no)
16. `monthly_therapy`: Number of therapy sessions attended monthly
17. `recent_major_events`: Recent major life events (yes/no)
18. `diet_quality`: Diet quality (scale of 1 to 10)
19. `anxiety_level`: Self-reported anxiety level (scale of 1 to 10)

Several pre-processing steps were needed before moving onto subsequent stages. First, four physiological variables - `heart_rate`, `breathing_rate`, `sweating_level`, and `dizziness` - were excluded from the set of predictors. This decision was based on the lack of documentation about how and when these measures were recorded. For instance, it is unclear whether they reflect real-time values reported during the survey or past measurements, which raises concerns about their reliability and interpretability. Moreover, while such indicators can be associated with anxiety, they tend to fluctuate only during or in anticipation of anxiety-inducing social situations, rather than serving as consistent markers. As a result, they were deemed unsuitable as predictors.

The original response variable, `anxiety_level`, ranges from 1 to 10 and appears continuous, but is more appropriately treated as ordinal. However, with 10 categories and unclear distinctions between adjacent levels (for example, anxiety level 3 versus 4), it posed challenges for interpretation and modeling. As such, a binary variable, `anxiety_status`, was created: participants with an anxiety level from 1 to 5 were labeled "Low," and those with levels 6 to 10 were labeled "High." The original `anxiety_level` variable was then removed and replaced with `anxiety_status` as the primary response variable.

After pre-processing, the final dataset has 11,000 observations and 15 variables. A random 80% of the dataset, corresponding to 8,800 observations, was used to train the models, while the remaining 20% (2,200 observations) was reserved for testing their performance.

## 2.2. Methodology

Dichotomizing the response variable transforms the problem into a classification task, where the goal is to predict the anxiety status of a participant (low or high) based on the remaining variables in the dataset. Several machine learning models were considered for this purpose:

- K-nearest neighbors: A simple learning algorithm that classifies a data point based on the majority class of its nearest neighbors. It is non-parametric and makes no assumptions about data distributions.

- Logistic regression: A widely used statistical model for binary classification. It provides interpretable coefficients and is suitable for understanding the influence of each predictor on the probability of high anxiety.

- Random forest: An ensemble method that builds multiple decision trees and aggregates their predictions. It handles non-linear relationships well, is robust to ovefitting, and provides variable importance measures, making it ideal for complex datasets.

- Bagging: An ensemble method that trains multiple versions of a model on different bootstrapped subsets of the training data. 

- Boosting: An ensemble method that builds models sequentially, where each new model focuses on correcting the errors made by the previous ones. It combines many weak trees (weak learners) into a strong learner. 
 
- Support vector classifier: A linear classifier that finds the optimal hyperplane to separate classes. 

- Support vector machine with a polynomial kernel: It extends the linear classifier to capture more complex relationships using polynomial transformations. It is useful when the decision boundary is non-linear but still relatively smooth.

- Support vector machine with a radial kernel: A powerful non-linear classifier that maps input features into a higher-dimensional space. It is well-suited for capturing complex patterns when the relationship between predictors and anxiety status is highly non-linear.

To evaluate model performance, a 10-fold cross-validation procedure was employed, using misclassification rate as the initial metric. However, exploratory data analysis revealed an imbalance in the response variable, making misclassification rate alone insuffucient for a comprehensive assessment. Therefore, additional metrics - sensitivity, specificity, F1 score, and the ROC curve - were also used to provide a more balanced and informative evaluation of each modelâ€™s predictive ability.

## 2.3. Software

All data analysis steps were performed using R version 4.3.1, along with additional packages that will be cited in the reference section.

# 3. Results

## 3.1. Exploratory Data Analysis

First, the distributions of numeric variables were investigated. It was found that only sleep hours followed a normal distribution. This discrepancy means that certain statistical learning methods, such as linear discriminant analysis and quadratic discriminant analysis, may not be suitable, as they assume that the predictors are normally distributed. The distributions also reveal that participants tend to report higher stress levels, while their diet quality is generally on the lower end of the scale.

```{r, fig.width = 10, fig.height = 6}
# define new variable names for numeric variables
num_labels <- c(
  "Age",
  "Sleep hours",
  "Physical hours",
  "Daily caffeine intake",
  "Weekly alcohol intake",
  "Stress Level",
  "Monthly therapy visits",
  "Diet Quality"
)

# map old variable names to new labels 
old_vars <- names(anxiety_n %>% select(where(is.numeric))) # obtain old variable names
name_map <- setNames(num_labels, old_vars)  

# plot distribution of numeric variables
anxiety_n %>%
  select(where(is.numeric)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "value") %>%
  mutate(variable = factor(variable, levels = old_vars, labels = num_labels)) %>%  # Map old names to new names
  ggplot(aes(x = value)) +
  geom_histogram(fill = "#6D9EC1", color = "white", bins = 30) +
  facet_wrap(~ variable, scales = "free", ncol = 4) +
  labs(
    title = "Distributions of Numeric Variables",
    x = "",
    y = "") +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5)
  )
```

The correlation matrix for the numeric variables shows no strong correlations among them, suggesting that multicollinearity is not a concern.

```{r, fig.width = 10, fig.height = 6}
# compute the correlation matrix 
corr_mat <- round(cor(anxiety_n %>% select(where(is.numeric))), 2)  # select only numeric predictors

# apply new variable names to the correlation matrix
colnames(corr_mat) <- num_labels
rownames(corr_mat) <- num_labels

# display the correlation matrix
ggcorrplot(
  corr_mat,
  method = "square",
  ggtheme = ggplot2::theme_minimal,
  title = "Correlation Matrix Between Numeric Predictors",
  colors = c("#6D9EC1", "white", "#E46726"),
  lab = T,
  lab_col = "#424242",
  show.legend = F
) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5)
  )

```

Next, the categorical variables were examined. Given the pre-processing done by the dataset distributor, itâ€™s not surprising that the categorical variables exhibit relatively equal proportions across different levels. The only exception is anxiety status, where there is a significantly lower number of individuals categorized as having high anxiety.

```{r, fig.width = 10, fig.height = 6}
# define new variable names
cat_labels <- c(
  "Gender",
  "Occupation",
  "Smoking",
  "Family History of Anxiety",
  "Medication",
  "Recent major life events",
  "Anxiety Status"
)

# map old variable names to new labels 
old_vars <- names(anxiety_n %>% select(where(~ is.factor(.) || is.character(.)))) # obtain old variable names
name_map <- setNames(cat_labels, old_vars)  

# plot bar charts of categorical variables/factors
anxiety_n %>%
  select(all_of(old_vars)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "value") %>%
  mutate(variable = factor(variable, levels = old_vars, labels = cat_labels)) %>%
  ggplot(aes(x = value)) +
  geom_bar(fill = "#6D9EC1", color = "white") +
  facet_wrap(~ variable, scales = "free", ncol=4) +
  labs(
    title = "Distributions of Categorical Variables",
    x = "",
    y = ""
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```

## 3.2. Model Comparison

Different models were trained using the training set and their respective predictive performance were tested on a test data using 10-fold cross validation and across different metrics. A good model would have low misclassification rate. As mentioned before, since the anxiety status is imbalanced, an additional metric is needed, which is the F1 score. The best model would have a highest F1 score, as a high F1 score means the model best balances precision (of all the positive predictions made, how many were actually correct?) and recall/sensitivity (of all the actual positive cases, how many were correctly identified by the model?). 

Based on the table below, it is evident that the logistic regression is the best model as it has the lowest misclassifcation rate and the highest F1 score among the models being considered. The next best model would be the support vector classifier. 

```{r}
# define some repetitive parts
formula <- anxiety_status ~ . # model
cv_10fold <- trainControl(method = "cv", 10) # 10-fold cross-validation
std <- c("center", "scale") # standardization of numeric variables
```

```{r}
set.seed(123)

# fit a knn model
knn <- train(
  formula,
  data = train_data,
  method = "knn",
  preProcess = std,
  trControl = cv_10fold,
  tuneGrid = data.frame(k = seq(10, 50, 1))
)

```

```{r}
set.seed(123)

# fit a logistic model
logit <- train(
  formula,
  data = train_data,
  method = "glm",
  family = "binomial",
  trControl = cv_10fold
)

```

```{r}
set.seed(123)

# fit a random forest model
rf <- train(
  formula,
  data = train_data,
  method = "rf",
  trControl = cv_10fold,
  ntree = 100,
  tuneGrid = data.frame(mtry = c(1:14))
)

```

```{r}
set.seed(123)

# fit a bagging model
bagging <- train(
  formula,
  data = train_data,
  method = "rf",
  trControl = cv_10fold,
  ntree = 100,
  tuneGrid = data.frame(mtry = 14)
)

```

```{r}
set.seed(123)

# fit a boosting model
boosting <- train(
  formula,
  data = train_data,
  method = "gbm",
  trControl = cv_10fold,
  tuneGrid = expand.grid(
    n.trees = seq(100, 500, 100),
    interaction.depth = c(3, 5, 10),
    shrinkage = c(0.01, 0.1, 0.25),
    n.minobsinnode = 10
  ),
  verbose = F
)

```

```{r}
set.seed(123)

# fit an svc model
svc <- train(
  formula, 
  data = train_data,
  method = "svmLinear",
  preProcess = std,
  trControl = trainControl("cv", 10, classProbs = TRUE), # add `classProbs` argument to obtain probabilities for plotting ROC curve
  tuneGrid = data.frame(C = c(0.01, 0.1, 1, 10))
)

```

```{r}
set.seed(123)

# fit an svm model with polynomial kernel
svm_poly <- train(
  formula,
  data = train_data,
  method = "svmPoly",
  trControl = trainControl("cv", 10, classProbs = TRUE),
  preProcess = std,
  tuneGrid = expand.grid(C = c(0.01, 0.1, 1, 10),
                         scale = c(0.01, 0.1),
                         degree = 2:4)
)

```

```{r}
set.seed(123)

# fit an svm model with radial kernel
svm_rad <- train(
  formula,
  data = train_data,
  method = "svmRadial",
  trControl = trainControl("cv", 10, classProbs = TRUE),
  preProcess = std,
  tuneGrid = expand.grid(C = c(0.01, 0.1, 1, 10),
                         sigma = c(0.01, 0.1, 0.5))
)

```

```{r}
########## MAKE PREDICTIONS USING DIFFERENT MODELS
# define list of models
mods <- list(knn = knn, logit = logit, rf = rf, bagging = bagging, boosting = boosting, 
             svc = svc, svm_poly = svm_poly, svm_rad = svm_rad)

# write a function
predict_mods <- function(model) {
  predict(model, newdata = test_data)
}

# apply the function
preds <- lapply(mods, predict_mods)

# combine predictions into a dataframe
preds_df <- as.data.frame(preds)
```

```{r}
########## CALCULATE MISCLASSIFICATION RATES FOR DIFFERENT MODELS
# write a function
calculate_miss_rate <- function(preds) {
  mean(preds != test_data$anxiety_status)
}

# apply the function
misclass_results <- sapply(preds_df, calculate_miss_rate)
```

```{r}
########## CALCULATE OTHER METRICS FOR MODEL EVALUATION
# write a function to extract sensitivity, specificity, precision, recall, and f1 score
get_metrics <- function(preds) {
  cm <- confusionMatrix(preds, test_data$anxiety_status, positive = "High")
  
  # extract sensitivity, specificity, precision, recall, and f1 score
  sensitivity <- cm$byClass["Sensitivity"]
  specificity <- cm$byClass["Specificity"]
  precision <- cm$byClass["Precision"]
  recall <- sensitivity  # recall = sensitivity
  f1_score <- cm$byClass["F1"]
  
  # return the metrics
  c(sens = sensitivity, spec = specificity, f1 = f1_score)
}

# apply the function
metrics <- sapply(preds_df, get_metrics)

# convert it to a dataframe and display 
as.data.frame(t(metrics),) %>%
  mutate(
    Model = c("K-nearest neighbors", "Logistic regression", "Random forest", "Bagging", "Boosting", 
              "SVC", "SVM with polynomial kernel", "SVM with radial kernel"), .before = 1,
    miss_rate = misclass_results
  ) %>%
  gt() %>%
  gtExtras::gt_theme_nytimes() %>%
  cols_align(c(2:5), align = "center") %>%
  cols_label(
    miss_rate = "Misclassification Rate",
    sens.Sensitivity = "Sensitivity",
    spec.Specificity = "Specificity",
    f1.F1 = "F1 SCore"
  ) %>%
  fmt_number(everything(), decimals = 4) %>%
  # highlight lowest misclassification rate
  tab_style(
    style = cell_fill(color = "#D6EAF8"),
    locations = cells_body(columns = miss_rate,
                           rows = miss_rate == min(miss_rate, na.rm = TRUE))
  ) %>%
  # highlight highest sensitivity
  tab_style(
    style = cell_fill(color = "#D6EAF8"),
    locations = cells_body(columns = sens.Sensitivity,
                           rows = sens.Sensitivity == max(sens.Sensitivity, na.rm = TRUE))
  ) %>%
  # highlight highest specificity
  tab_style(
    style = cell_fill(color = "#D6EAF8"),
    locations = cells_body(columns = spec.Specificity,
                           rows = spec.Specificity == max(spec.Specificity, na.rm = TRUE))
  ) %>%
  # highlight highest f1 Score
  tab_style(
    style = cell_fill(color = "#D6EAF8"),
    locations = cells_body(columns = f1.F1,
                           rows = f1.F1 == max(f1.F1, na.rm = TRUE))
  )  %>%
  tab_caption(caption = "Table 1.Comparison of Different Models across Different Metrics")
```

When plotting the ROC curves for the different models, it is apparent that logistic regression once again emerges as the top contender as it has the highest area under the curve (AUC). This also indicates that the model is highly capable of distringuishing between positive and negative classes perfectly.  

```{r, fig.width = 12, fig.height = 8}
# write a function to calculate predicted probabilities
predict_probs_mods <- function(model) {
  predict(model, newdata = test_data, type = "prob")$High
}

# apply the function
probs_mods <- lapply(mods, predict_probs_mods)
probs_mods_df <- as.data.frame(probs_mods) # convert to a dataframe 

model_names <- c("K-nearest neighbors", "Logistic regression", "Random forest", "Bagging", "Boosting", 
              "SVC", "SVM with polynomial kernel", "SVM with radial kernel")

# generate ROC curves for each model
roc_list <- lapply(1:length(probs_mods_df), function(i) {
  roc(test_data$anxiety_status, probs_mods_df[[i]], levels = c("Low", "High"))
})

par(mfrow = c(2, 4))

# plot each ROC curve with AUC
for (i in 1:length(roc_list)) {
  auc_val <- round(auc(roc_list[[i]]), 3)
  plot(roc_list[[i]],
       main = paste(model_names[i], "- AUC =", auc_val),
       col = i,
       lwd = 2)
}

```

Since logistic regression comes out as the best model, it can be fitted on the whole data to identify meaningful predictors. Let's examine the summary output of the logistic model to see which variables are important at predicting high anxiety. It appears that lifestyle factors play a significant role in predicting high social anxiety. Variables such as diet quality, sleep duration, physical activity, caffeine intake, and alcohol consumption were all found to be statistically significant predictors. For each additional sleep hours, the log-odds of being in the "high" anxiety group decrease by 0.75, which is reasonable as more sleep is supposed to help with lower anxiety. The same pattern occurs for weekly hours spent on physical activity - each additional weekly hour of physical activity is associated with a 0.118 decrease in the log odds of being in the "high" anxiety group - and is also understandable because physical activity is usually thought to reduce anxiety. Increase in caffeine intake and alcohol assumption are linked with increasing chances of being in the high anxiety level, which is not surprising considering that caffeine usually worsen anxiety symptoms like nervousness, restlessness, or racing thoughts. Additionally, increased stress level is shown to lead to higher chances of being in the high anxiety group as well. 

The model also suggests a slight decrease in the probability of high anxiety with age, which again is not counter-intuitive given that older individuals often manage social situations better due to experience. It is interesting to note that individuals in high-intensity occupations, such as doctors or engineers, appear less prone to elevated social anxiety. This could be because these roles often demand individuals with strong mental resilience and problem-solving skills, potentially reducing their vulnerability to social anxiety. Therefore, this outcome may reflect reverse causality; people in these fields are already accustomed to pressure and so they are more resistant to social anxiety, not that people will have a lower chance of being placed in the "high" anxiety group if they are doctors and engineers. It is interesting to note that another high-stress profession like lawyer is not statistically significant at the 0.05 level ($p$-value = 0.0514), but its proximity to the threshold suggests it could be of interest in future research. 

Unexpectedly, more therapy sessions are associated with a higher chance of high anxiety. This might be a case of reverse causality as people with higher anxiety might be more likely to attend therapy in the first place. If this is the case, the model is capturing the fact that those with more anxiety are more likely to attend therapy, not necessarily that therapy causes higher chance of an individual being placed in the high anxiety group.  

```{r}
# refit logistic regression
logit_full <- train(
  formula,
  data = anxiety_n,
  method = "glm",
  family = "binomial"
)

coef_df <- as.data.frame(summary(logit_full)$coefficients)
coef_df$vars <- rownames(coef_df)

as.data.frame(coef_df) %>%
  select(vars, c(1:2, 4)) %>%
  gt() %>%
  gtExtras::gt_theme_espn() %>%
  cols_align(c(2:4), align = "center") %>%
  cols_label(vars = "Coefficients") %>%
  fmt_number(everything(), decimals = 4) %>%
  tab_style(
    style = list(cell_fill(color = "#D6EAF8")),
    locations = cells_body(columns = everything(),
                           rows = coef_df$`Pr(>|z|)` < 0.05)
  ) %>%
  tab_caption("Table 2. Coefficient Estimates of Logistic Regression")
```


# 4. Conclusion & Caveats

After trying different models, the logistic regression was chosen as the best model in terms of predictive ability and balance between precision and recall. The model also provided insights into which variables were important predictors of high anxiety. Notably, lifestyle-related variables emerged as significant predictors, emphasizing the critical role that daily habits, such as sleep, diet, and physical activityâ€”play in shaping mental health. These findings underscore the importance of maintaining a healthy and balanced lifestyle as a potential means of reducing the risk of social anxiety.

Nonetheless, despite meaningful findings, it is important to acknowledge limitations within this report. Firstly, the analysis identifies associations between predictors and anxiety status but does not establish causal relationships. For instance, while the logistic regression suggests therapy sessions may be associated with higher anxiety, this does not imply that therapy causes higher anxiety. Other factors, like the severity of anxiety or the type of therapy, may be influencing this relationship. Therefore, future longitudinal or experimental studies would be required to determine causal effects.

Many of the variables, such as stress level, diet quality, and so on, are based on self-report, which may introduce bias due to inaccurate recall or individual differences in how people interpret or report their experiences.  Moreover, the lack of clear documentation regarding the survey administration introduces another layer of potential sampling bias, which further complicates the ability to generalize these findings to a broader or more defined population. 

# 5. References

Monteiro, T. (2025, March 21). Social Anxiety Dataset. Kaggle. https://www.kaggle.com/datasets/natezhang123/social-anxiety-dataset/data?select=enhanced_anxiety_dataset.csv 

R Core Team (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/.

Kuhn, M. (2008). Building Predictive Models in R Using the caret Package. Journal of Statistical Software, 28(5), 1â€“26. https://doi.org/10.18637/jss.v028.i05
  
Wickham H, Francois R, Henry L, Muller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.3, <https://CRAN.R-project.org/package=dplyr>.

Schloerke B, Cook D, Larmarange J, Briatte F, Marbach M, Thoen E, Elberg A, Crowley J (2024). _GGally: Extension to 'ggplot2'_. R package version 2.2.1, <https://CRAN.R-project.org/package=GGally>.

Kassambara A (2023). _ggcorrplot: Visualization of a Correlation Matrix using 'ggplot2'_. R package version 0.1.4.1, <https://CRAN.R-project.org/package=ggcorrplot>.

H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016.

Iannone R, Cheng J, Schloerke B, Hughes E, Lauer A, Seo J (2024). _gt: Easily Create Presentation-Ready Display Tables_. R package version 0.10.1, <https://CRAN.R-project.org/package=gt>.

Xavier Robin, Natacha Turck, Alexandre Hainard, Natalia Tiberti, FrÃ©dÃ©rique Lisacek, Jean-Charles Sanchez and Markus MÃ¼ller (2011). pROC: an open-source package for R and S+ to analyze and compare ROC curves. BMC Bioinformatics, 12, p. 77.  DOI: 10.1186/1471-2105-12-77 <http://www.biomedcentral.com/1471-2105/12/77/>

Wickham H, Vaughan D, Girlich M (2023). _tidyr: Tidy Messy Data_. R package version 1.3.0, <https://CRAN.R-project.org/package=tidyr>.

